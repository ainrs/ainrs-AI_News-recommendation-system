import os
import logging
import uuid
from fastapi import FastAPI, HTTPException, Depends, BackgroundTasks, Query
from fastapi.middleware.cors import CORSMiddleware
from typing import List, Dict, Any, Optional
from datetime import datetime
from pydantic import BaseModel

from app.core.config import settings
from app.db.mongodb import news_collection, user_collection, user_interactions_collection, get_mongodb_database
from bson.objectid import ObjectId
from app.models.news import NewsResponse, NewsSummary, NewsSearchQuery
from app.services.rss_crawler import run_crawler

# ì„œë¹„ìŠ¤ ê°€ì ¸ì˜¤ê¸°
from app.services.embedding_service import get_embedding_service
from app.services.recommendation_service import get_recommendation_service
from app.services.user_analytics import get_user_analytics_service
from app.services.rag_service import get_rag_service
from app.services.collaborative_filtering import get_collaborative_filtering_service
from app.services.trust_analysis_service import get_trust_analysis_service
from app.services.sentiment_analysis_service import get_sentiment_analysis_service
from app.services.langchain_service import get_langchain_service
from app.services.vector_store_service import get_vector_store_service
from app.services.model_controller_service import get_model_controller_service
from app.services.scheduler import get_scheduler_service
from app.services.hybrid_recommendation import get_hybrid_recommendation_service
from app.services.system_prompt import get_system_prompt
from app.services.bert4rec_service import get_bert4rec_service

# ë¼ìš°í„° ê°€ì ¸ì˜¤ê¸°
from app.routers import news, users, admin, recommendation, auth, email_verification

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create data directory if it doesn't exist
os.makedirs(settings.DATA_DIR, exist_ok=True)

# Initialize FastAPI app
app = FastAPI(
    title=settings.PROJECT_NAME,
    openapi_url=f"{settings.API_V1_STR}/openapi.json"
)

# ì‹œì‘ ë¡œê·¸
logger.info(f"ì„œë²„ ì‹œì‘ ì¤‘...")
logger.info(f"OpenAI API í‚¤ ì„¤ì •ë¨: {'ì˜ˆ' if settings.OPENAI_API_KEY else 'ì•„ë‹ˆì˜¤'}")
logger.info(f"ë°ì´í„° ë””ë ‰í† ë¦¬: {settings.DATA_DIR}")
logger.info(f"API ê²½ë¡œ: {settings.API_V1_STR}")

# ëª½ê³ ë””ë¹„ ì—°ê²° í™•ì¸
try:
    # connection í™•ì¸
    from pymongo import MongoClient
    client = MongoClient(settings.MONGODB_URI)
    # ping ëª…ë ¹ìœ¼ë¡œ ì—°ê²° ìƒíƒœ í™•ì¸
    client.admin.command('ping')
    logger.info(f"âœ… MongoDB ì—°ê²° ì„±ê³µ")
except Exception as e:
    logger.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {str(e)}")

# Add CORS middleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  ì˜¤ë¦¬ì§„ í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
    expose_headers=["*"],  # í”„ë¡ íŠ¸ì—”ë“œì— ë…¸ì¶œí•  í—¤ë”
)

# Dependency to get embedding service
def get_embedding_service_dep():
    return get_embedding_service()

# Dependency to get recommendation service
def get_recommendation_service_dep():
    return get_recommendation_service()

# Dependency to get user analytics service
def get_user_analytics_service_dep():
    return get_user_analytics_service()

# Dependency to get RAG service
def get_rag_service_dep():
    return get_rag_service()

# Dependency to get collaborative filtering service
def get_collaborative_filtering_service_dep():
    return get_collaborative_filtering_service()

# Dependency to get trust analysis service
def get_trust_analysis_service_dep():
    return get_trust_analysis_service()

# Dependency to get sentiment analysis service
def get_sentiment_analysis_service_dep():
    return get_sentiment_analysis_service()

# Dependency to get LangChain service
def get_langchain_service_dep():
    return get_langchain_service()

# Dependency to get vector store service
def get_vector_store_service_dep():
    return get_vector_store_service()

# Dependency to get model controller service
def get_model_controller_service_dep():
    return get_model_controller_service()

# Dependency to get scheduler service
def get_scheduler_service_dep():
    return get_scheduler_service()

# Dependency to get hybrid recommendation service
def get_hybrid_recommendation_service_dep():
    return get_hybrid_recommendation_service()

# Dependency to get system prompt
def get_system_prompt_dep():
    return get_system_prompt()

# ë¼ìš°í„° ë“±ë¡
app.include_router(news.router, prefix="/api/v1")
app.include_router(users.router, prefix="/api/v1")
app.include_router(admin.router, prefix="/api/v1")
app.include_router(recommendation.router, prefix="/api/v1")
app.include_router(auth.router, prefix="/api/v1")
app.include_router(email_verification.router, prefix="/api/v1")

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬
@app.on_event("startup")
async def startup_event():
    """ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì‹œ ì‹¤í–‰ë˜ëŠ” ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬"""
    logger.info("ğŸš€ ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘ ì´ë²¤íŠ¸ ì‹¤í–‰")

    # ìŠ¤ì¼€ì¤„ëŸ¬ ì„œë¹„ìŠ¤ ì‹œì‘
    try:
        scheduler_service = get_scheduler_service()
        scheduler_service.start()
        logger.info("âœ… ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ë¨")
    except Exception as e:
        logger.error(f"âŒ ìŠ¤ì¼€ì¤„ëŸ¬ ì‹œì‘ ì˜¤ë¥˜: {e}")

    # ì´ˆê¸° ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤í–‰ (ì¦‰ì‹œ ì‹¤í–‰)
    try:
        # ì§ì ‘ í¬ë¡¤ëŸ¬ ì‹¤í–‰
        article_count = run_crawler()
        logger.info(f"âœ… ì´ˆê¸° ë‰´ìŠ¤ í¬ë¡¤ë§ ì™„ë£Œ: {article_count}ê°œ ê¸°ì‚¬ ê°€ì ¸ì˜´")

        # BERT4Rec ì„œë¹„ìŠ¤ë¡œ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ë°ì´í„° ì´ˆê¸°í™”
        try:
            bert4rec_service = get_bert4rec_service()
            bert4rec_service.initialize_cold_start_recommendations()
            logger.info("âœ… ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ë°ì´í„° ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as rec_error:
            logger.error(f"âŒ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {rec_error}")

        # API ì—”ë“œí¬ì¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ í‘œì‹œ
        # ì´ë ‡ê²Œ í•˜ë©´ í¬ë¡¤ë§ì´ ì™„ë£Œëœ í›„ì— API ì—”ë“œí¬ì¸íŠ¸ê°€ ì‘ë‹µí•˜ê¸° ì‹œì‘í•¨
        logger.info("ğŸ”Œ API ì—”ë“œí¬ì¸íŠ¸ ì¤€ë¹„ ì™„ë£Œ - í´ë¼ì´ì–¸íŠ¸ ìš”ì²­ ìˆ˜ì‹  ê°€ëŠ¥")
    except Exception as e:
        logger.error(f"âŒ ì´ˆê¸° ë‰´ìŠ¤ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")

# ì—°ê²° ì§„ë‹¨ì„ ìœ„í•œ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/v1/diagnostics")
async def run_diagnostics():
    """ì‹œìŠ¤í…œ ì—°ê²° ìƒíƒœë¥¼ ì§„ë‹¨í•©ë‹ˆë‹¤."""
    results = {
        "mongodb": {"status": "unknown", "error": None},
        "openai_api": {"status": "unknown", "error": None},
        "embedding_service": {"status": "unknown", "error": None},
        "vector_store": {"status": "unknown", "error": None},
        "timestamp": datetime.utcnow().isoformat()
    }

    # MongoDB ì—°ê²° í™•ì¸
    try:
        db = await get_mongodb_database()
        # ë°ì´í„°ë² ì´ìŠ¤ ping í…ŒìŠ¤íŠ¸
        await db.command("ping")
        # ì»¬ë ‰ì…˜ í™•ì¸
        collections = await db.list_collection_names()
        results["mongodb"]["status"] = "connected"
        results["mongodb"]["collections"] = collections
        results["mongodb"]["count"] = {
            "news": await db["news"].count_documents({}),
            "users": await db["users"].count_documents({})
        }
    except Exception as e:
        results["mongodb"]["status"] = "error"
        results["mongodb"]["error"] = str(e)
        logger.error(f"MongoDB ì—°ê²° ì˜¤ë¥˜: {str(e)}")

    # OpenAI API ì—°ê²° í™•ì¸
    try:
        from openai import OpenAI
        client = OpenAI(api_key=settings.OPENAI_API_KEY)
        # ê°„ë‹¨í•œ API í˜¸ì¶œë¡œ ì—°ê²° í…ŒìŠ¤íŠ¸
        response = client.embeddings.create(
            model="text-embedding-3-small",
            input="í…ŒìŠ¤íŠ¸"
        )
        results["openai_api"]["status"] = "connected"
        results["openai_api"]["model"] = "text-embedding-3-small"
    except Exception as e:
        results["openai_api"]["status"] = "error"
        results["openai_api"]["error"] = str(e)
        logger.error(f"OpenAI API ì—°ê²° ì˜¤ë¥˜: {str(e)}")

    # ì„ë² ë”© ì„œë¹„ìŠ¤ í™•ì¸
    try:
        embedding_service = get_embedding_service()
        test_embedding = await embedding_service.get_embedding("í…ŒìŠ¤íŠ¸")
        if test_embedding and len(test_embedding) > 0:
            results["embedding_service"]["status"] = "working"
            results["embedding_service"]["embedding_size"] = len(test_embedding)
        else:
            results["embedding_service"]["status"] = "error"
            results["embedding_service"]["error"] = "ì„ë² ë”© ìƒì„± ì‹¤íŒ¨"
    except Exception as e:
        results["embedding_service"]["status"] = "error"
        results["embedding_service"]["error"] = str(e)
        logger.error(f"ì„ë² ë”© ì„œë¹„ìŠ¤ ì˜¤ë¥˜: {str(e)}")

    # ë²¡í„° ì €ì¥ì†Œ í™•ì¸
    try:
        import os
        vector_store_service = get_vector_store_service()
        chroma_path = os.path.join(settings.DATA_DIR, "chroma")
        faiss_path = os.path.join(settings.DATA_DIR, "faiss")

        results["vector_store"]["status"] = "partial"
        results["vector_store"]["paths"] = {
            "chroma_exists": os.path.exists(chroma_path),
            "chroma_path": chroma_path,
            "faiss_exists": os.path.exists(faiss_path),
            "faiss_path": faiss_path
        }

        if os.path.exists(chroma_path) and os.path.exists(faiss_path):
            results["vector_store"]["status"] = "ready"

    except Exception as e:
        results["vector_store"]["status"] = "error"
        results["vector_store"]["error"] = str(e)
        logger.error(f"ë²¡í„° ì €ì¥ì†Œ í™•ì¸ ì˜¤ë¥˜: {str(e)}")

    # ì „ì²´ ì‹œìŠ¤í…œ ìƒíƒœ íŒë‹¨
    all_ok = all(results[component]["status"] in ["connected", "working", "ready"]
                 for component in ["mongodb", "openai_api", "embedding_service", "vector_store"])

    if all_ok:
        results["overall_status"] = "ok"
    elif results["mongodb"]["status"] != "connected":
        results["overall_status"] = "critical"
    else:
        results["overall_status"] = "degraded"

    return results

# ìˆ˜ë™ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì—”ë“œí¬ì¸íŠ¸
@app.post("/api/v1/admin/run-crawler")
async def manual_run_crawler():
    """RSS í¬ë¡¤ëŸ¬ë¥¼ ìˆ˜ë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤."""
    try:
        article_count = run_crawler()
        return {"success": True, "message": f"í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì„±ê³µ: {article_count}ê°œ ê¸°ì‚¬ ìˆ˜ì§‘ë¨"}
    except Exception as e:
        logger.error(f"âŒ ìˆ˜ë™ í¬ë¡¤ëŸ¬ ì‹¤í–‰ ì˜¤ë¥˜: {e}")
        return {"success": False, "error": str(e)}

@app.get("/")
def read_root():
    return {"message": "Welcome to AI News Recommendation System"}


@app.get("/api/v1/health")
async def health_check():
    # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í™•ì¸
    db_status = "ok"
    mongodb_error = None
    try:
        # DB ì—°ê²° í…ŒìŠ¤íŠ¸
        db = await get_mongodb_database()
        await db.command("ping")
    except Exception as e:
        db_status = "error"
        mongodb_error = str(e)

    # OpenAI API í‚¤ í™•ì¸
    openai_api_status = "ok" if settings.OPENAI_API_KEY else "not_configured"

    # ìì„¸í•œ ìƒíƒœ ë°˜í™˜
    return {
        "status": "ok" if db_status == "ok" and openai_api_status == "ok" else "degraded",
        "components": {
            "api": "ok",
            "database": db_status,
            "database_error": mongodb_error,
            "openai_api": openai_api_status
        },
        "timestamp": datetime.utcnow().isoformat()
    }


@app.post("/api/v1/crawl")
async def crawl_news(background_tasks: BackgroundTasks):
    """Crawl news from RSS feeds"""
    background_tasks.add_task(run_crawler)
    return {"message": "News crawling started in background"}


@app.get("/api/v1/news", response_model=List[NewsResponse])
async def get_news(
    background_tasks: BackgroundTasks,
    skip: int = 0,
    limit: int = 10,
    source: Optional[str] = None,
    category: Optional[str] = None
):
    """Get list of news articles"""
    logger.info(f"ë‰´ìŠ¤ ëª©ë¡ ìš”ì²­: limit={limit}, category={category}, source={source}")

    try:
        query = {}
        if source:
            query["source"] = source

        # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ ë¡œì§ ìˆ˜ì • - ì¹´í…Œê³ ë¦¬ ë°°ì—´ì— í¬í•¨ëœ í•­ëª© ê²€ìƒ‰
        if category:
            query["categories"] = {"$in": [category]}  # ë°°ì—´ ë‚´ì— ì¹´í…Œê³ ë¦¬ê°€ í¬í•¨ëœ í•­ëª© ê²€ìƒ‰
            logger.info(f"ì¹´í…Œê³ ë¦¬ í•„í„°ë§: {category}, ì¿¼ë¦¬: {query}")

        # ë°ì´í„°ë² ì´ìŠ¤ ìƒíƒœ í™•ì¸
        total_news_count = news_collection.count_documents({})
        logger.info(f"ì „ì²´ ë‰´ìŠ¤ ìˆ˜: {total_news_count}ê°œ")

        # ì¿¼ë¦¬ì— í•´ë‹¹í•˜ëŠ” ë‰´ìŠ¤ ê°œìˆ˜ í™•ì¸
        filtered_count = news_collection.count_documents(query)
        logger.info(f"í•„í„°ë§ëœ ë‰´ìŠ¤ ìˆ˜: {filtered_count}ê°œ")

        # ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸° - ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬
        news = list(news_collection.find(query).skip(skip).limit(limit).sort("published_date", -1))
        logger.info(f"ë‰´ìŠ¤ ì¿¼ë¦¬ ê²°ê³¼: {len(news)}ê°œ í•­ëª©")

        # ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš°
        if not news:
            logger.warning(f"ì¼ì¹˜í•˜ëŠ” ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì¿¼ë¦¬: {query}")
            # ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìœ¼ë©´ í¬ë¡¤ëŸ¬ ì‹¤í–‰
            if total_news_count == 0:
                logger.info("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. í¬ë¡¤ëŸ¬ë¥¼ ìë™ìœ¼ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤.")
                background_tasks.add_task(run_crawler)

        result = []
        for item in news:
            # í•„ìˆ˜ í•„ë“œì— ê¸°ë³¸ê°’ í• ë‹¹ (ìœ íš¨ì„± ê²€ì‚¬ ì˜¤ë¥˜ ë°©ì§€)
            if "image_url" not in item or not item.get("image_url"):
                item["image_url"] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZAAAADICAMAAAD2ShmzAAAAM1BMVEX////CwsL5+fnV1dXq6ur19fXg4OC8vLzT09Pt7e3Hx8fv7+/d3d3h4eHQ0NCwsLD///+ck8V3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAD90lEQVR4nO3di5KjIBCFYQREvEDf/2UX0E2ceGlAiQy6/1fTtZVJ1SQndjtBr7IcZ7TqfnAZHhODu1cP/92V0tpqEz6BePgzcb/+Qb01hSK9VQeQKU6e0iJ6VXpRfFcfoAlbRZoiCCKEAEIIIIQAQggghABCCCCEAEIIBYUwU0kGsZoG8k4yiNPf1f9bvWQQ70zpSnnBILZcnhTLBbGutBDLfXbFBmF/CJQMwiXtsiDcrLJXJYNYZkpCsQghgBACCCGAEAIIIYAQQgEhk9UVMGhMMVQ3qGsZbZ+HGqY53jJp90Nouo2HUL2O/6pqpjmGQx6R9PlbY8+GUJ0+GTTHJdIhVGfOhFCdP7OT6qYTi6NvRULcR3UkBnVbXOUexFd2LkTVdjnRV3ZqIGbLXnp2Jb5T8dwcPrM5F8It/Ft48yrR3HbVHQ+hvlqfFwihL5cA4SCr1J0B8UWnPTKhvtfAu9ZQCB2sU85rCcyH0Nl65GQIXaj+T4doCtL4jAL3hWzpkahZXLsxO2tRFoIyIKV6ZDaEZmwDQlUHQVyhQkNo3g4gtPCDNkdVIJdDXJt0Y5xXcmMOyjXIpZNIGj3mZQgVPd4IQttaCqG1zfI1EFoNGc6HUNnD8URIYJ8QYzAiFMStzZGlENrYvhLSl2t20qUQYm1hq+wVh0Jo4UgIre6PQ6jocYi+XGXXJZdBaN2i4iFUdkVSPy7axrIglHdZXz/OwpW3UrMg3aYP+6HdTjdX8g/SPU6hgx32P4imbKF0z0txA+bZ0e3FNuX3LtfucWhbkofVU+DhXPe4FN4vQcfz2e4JH1DQ5zt8KftFuSDgk6Ou/AxoG/HZ7Mu1ouD5N2f/rLYxe1DGCDxj6ux7yjdC5P1S4Dlt5y2TvTIQRzV7XuDZiVcfUCJ4q8qXy2EJ3yrK5aA7e6/MhfAfQxcAoYc4UWflw0BFNKcdJPjZJQgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBAWA8K9MlwI9ynhXqQsCOcXEWw3JQvCPRdcFMkgzEfJZZEMwv1g+EqJZBDuUcN+jgWDcL8h7rkkGYR7V3FPMO5lxEUSCXGPRuoNx0USCfd65d6zDIj+Moj+Moj+Moj+Moj+Moj++vMQ8tRCf/1lEP31l0H0FzV7YV9sMQ1Wf1Gz4QDC3XaYF1tUfGISrT91EUQI/WUQ/WUQ/WUQ/WUQ/UXNIJjfGYR5xUa0+NQZ1g8lzSCkGQT7uZ14Nd8QJt5fJIjDiqIAAAAASUVORK5CYII="

            if "categories" not in item or not item.get("categories"):
                item["categories"] = ["ì¸ê³µì§€ëŠ¥"]

            if "summary" not in item or not item.get("summary"):
                item["summary"] = item.get("title", "")[:100]

            if "content" not in item or not item.get("content"):
                item["content"] = item.get("title", "") + " (ìì„¸í•œ ë‚´ìš©ì€ ì›ë¬¸ì„ ì°¸ì¡°í•˜ì„¸ìš”.)"

            result.append(NewsResponse(
                id=item["_id"],
                title=item["title"],
                content=item.get("content", ""),
                url=item["url"],
                source=item["source"],
                published_date=item["published_date"],
                author=item.get("author", ""),
                image_url=item.get("image_url"),
                summary=item.get("summary"),
                categories=item.get("categories", ["ì¸ê³µì§€ëŠ¥"]),
                keywords=item.get("keywords", []),
                created_at=item["created_at"],
                updated_at=item["updated_at"],
                trust_score=item.get("trust_score", 0.5),
                sentiment_score=item.get("sentiment_score", 0),
                metadata=item.get("metadata", {})
            ))

        logger.info(f"ë‰´ìŠ¤ ì‘ë‹µ: {len(result)}ê°œ í•­ëª©")
        return result
    except Exception as e:
        logger.error(f"ë‰´ìŠ¤ ëª©ë¡ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        return []


@app.get("/api/v1/news/{news_id}", response_model=NewsResponse)
async def get_news_by_id(news_id: str):
    """Get a news article by ID"""
    # ë¨¼ì € ë¬¸ìì—´ IDë¡œ ì‹œë„
    news = news_collection.find_one({"_id": news_id})

    # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ObjectIdë¡œ ì‹œë„
    if not news:
        try:
            obj_id = ObjectId(news_id)
            news = news_collection.find_one({"_id": obj_id})
        except:
            # IDê°€ ë¬¸ìì—´ì¸ë° MongoDBì—ëŠ” ObjectIdë¡œ ì €ì¥ëœ ê²½ìš°
            # ë˜ëŠ” ê·¸ ë°˜ëŒ€ì˜ ê²½ìš°ë¥¼ ì²˜ë¦¬
            news = news_collection.find_one({"id": news_id})

    # ì—¬ì „íˆ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì—ëŸ¬
    if not news:
        raise HTTPException(status_code=404, detail="News not found")

    # ëˆ„ë½ëœ í•„ë“œ ì²˜ë¦¬
    if "image_url" not in news or not news.get("image_url"):
        news["image_url"] = "data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAZAAAADICAMAAAD2ShmzAAAAM1BMVEX////CwsL5+fnV1dXq6ur19fXg4OC8vLzT09Pt7e3Hx8fv7+/d3d3h4eHQ0NCwsLD///+ck8V3AAAACXBIWXMAAAsTAAALEwEAmpwYAAAD90lEQVR4nO3di5KjIBCFYQREvEDf/2UX0E2ceGlAiQy6/1fTtZVJ1SQndjtBr7IcZ7TqfnAZHhODu1cP/92V0tpqEz6BePgzcb/+Qb01hSK9VQeQKU6e0iJ6VXpRfFcfoAlbRZoiCCKEAEIIIIQAQggghABCCCCEAEIIBYUwU0kGsZoG8k4yiNPf1f9bvWQQ70zpSnnBILZcnhTLBbGutBDLfXbFBmF/CJQMwiXtsiDcrLJXJYNYZkpCsQghgBACCCGAEAIIIYAQQgEhk9UVMGhMMVQ3qGsZbZ+HGqY53jJp90Nouo2HUL2O/6pqpjmGQx6R9PlbY8+GUJ0+GTTHJdIhVGfOhFCdP7OT6qYTi6NvRULcR3UkBnVbXOUexFd2LkTVdjnRV3ZqIGbLXnp2Jb5T8dwcPrM5F8It/Ft48yrR3HbVHQ+hvlqfFwihL5cA4SCr1J0B8UWnPTKhvtfAu9ZQCB2sU85rCcyH0Nl65GQIXaj+T4doCtL4jAL3hWzpkahZXLsxO2tRFoIyIKV6ZDaEZmwDQlUHQVyhQkNo3g4gtPCDNkdVIJdDXJt0Y5xXcmMOyjXIpZNIGj3mZQgVPd4IQttaCqG1zfI1EFoNGc6HUNnD8URIYJ8QYzAiFMStzZGlENrYvhLSl2t20qUQYm1hq+wVh0Jo4UgIre6PQ6jocYi+XGXXJZdBaN2i4iFUdkVSPy7axrIglHdZXz/OwpW3UrMg3aYP+6HdTjdX8g/SPU6hgx32P4imbKF0z0txA+bZ0e3FNuX3LtfucWhbkofVU+DhXPe4FN4vQcfz2e4JH1DQ5zt8KftFuSDgk6Ou/AxoG/HZ7Mu1ouD5N2f/rLYxe1DGCDxj6ux7yjdC5P1S4Dlt5y2TvTIQRzV7XuDZiVcfUCJ4q8qXy2EJ3yrK5aA7e6/MhfAfQxcAoYc4UWflw0BFNKcdJPjZJQgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBBACAGEEEAIAYQQQAgBhBAWA8K9MlwI9ynhXqQsCOcXEWw3JQvCPRdcFMkgzEfJZZEMwv1g+EqJZBDuUcN+jgWDcL8h7rkkGYR7V3FPMO5lxEUSCXGPRuoNx0USCfd65d6zDIj+Moj+Moj+Moj+Moj+Moj++vMQ8tRCf/1lEP31l0H0FzV7YV9sMQ1Wf1Gz4QDC3XaYF1tUfGISrT91EUQI/WUQ/WUQ/WUQ/WUQ/UXNIJjfGYR5xUa0+NQZ1g8lzSCkGQT7uZ14Nd8QJt5fJIjDiqIAAAAASUVORK5CYII="

    return NewsResponse(
        id=news["_id"],
        title=news["title"],
        content=news["content"],
        url=news["url"],
        source=news["source"],
        published_date=news["published_date"],
        author=news.get("author"),
        image_url=news.get("image_url"),
        summary=news.get("summary"),
        categories=news.get("categories", []),
        keywords=news.get("keywords", []),
        created_at=news["created_at"],
        updated_at=news["updated_at"],
        trust_score=news.get("trust_score"),
        sentiment_score=news.get("sentiment_score"),
        metadata=news.get("metadata", {})
    )


@app.post("/api/v1/news/search", response_model=List[NewsSummary])
async def search_news(
    query: NewsSearchQuery,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """Search for news articles"""
    results = await recommendation_service.search_news(query)
    return results


@app.get("/api/v1/news/trending", response_model=List[NewsSummary])
async def get_trending_news(
    limit: int = 10,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """Get trending news articles"""
    logger.info(f"íŠ¸ë Œë”© ë‰´ìŠ¤ ìš”ì²­: limit={limit}")
    try:
        # ê¸°ë³¸ ë‰´ìŠ¤ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
        total_news_count = news_collection.count_documents({})
        if total_news_count == 0:
            logger.warning("ë‰´ìŠ¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. ë¹ˆ ëª©ë¡ ë°˜í™˜")
            return []

        trending = await recommendation_service.get_trending_news(limit)

        # ì¶”ì²œ ê²°ê³¼ê°€ ì—†ëŠ” ê²½ìš° ìµœì‹  ë‰´ìŠ¤ë¡œ ëŒ€ì²´
        if not trending or len(trending) == 0:
            logger.info("íŠ¸ë Œë”© ë‰´ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ìµœì‹  ë‰´ìŠ¤ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            recent_news = list(news_collection.find().sort("published_date", -1).limit(limit))
            trending = []

            for news in recent_news:
                summary = NewsSummary(
                    id=str(news["_id"]),
                    title=news["title"],
                    source=news["source"],
                    published_date=news["published_date"],
                    summary=news.get("summary", ""),
                    image_url=news.get("image_url", ""),
                    trust_score=news.get("trust_score", 0.5),
                    sentiment_score=news.get("sentiment_score", 0),
                    categories=news.get("categories", [])
                )
                trending.append(summary)

        logger.info(f"íŠ¸ë Œë”© ë‰´ìŠ¤ ì‘ë‹µ: {len(trending)}ê°œ í•­ëª©")
        return trending
    except Exception as e:
        logger.error(f"íŠ¸ë Œë”© ë‰´ìŠ¤ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ëª©ë¡ ë°˜í™˜
        return []


# ì´ ì—”ë“œí¬ì¸íŠ¸ëŠ” recommendation ë¼ìš°í„°ë¡œ ì´ë™í–ˆìŠµë‹ˆë‹¤.
# ì´ì „ ì½”ë“œì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ ìœ ì§€í•©ë‹ˆë‹¤.
@app.get("/api/v1/recommendations/{user_id}", response_model=List[NewsSummary])
async def get_recommendations(
    user_id: str,
    limit: int = 10,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """Get personalized recommendations for a user"""
    # ë¼ìš°í„°ë¡œ ì´ë™í•œ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©
    recommendations = await recommendation_service.get_personalized_recommendations(user_id, limit)
    return recommendations

# í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/v1/hybrid-recommendations/{user_id}", response_model=List[NewsSummary])
async def get_hybrid_recommendations(
    user_id: str,
    limit: int = 10,
    hybrid_recommendation_service: Any = Depends(get_hybrid_recommendation_service_dep)
):
    """Get hybrid recommendations for a user (content + collaborative)"""
    # í•˜ì´ë¸Œë¦¬ë“œ ì¶”ì²œ ìš”ì²­ì„ ì²˜ë¦¬í•©ë‹ˆë‹¤
    recommendations = await hybrid_recommendation_service.get_personalized_recommendations(user_id, limit)
    return recommendations

@app.post("/api/v1/interaction")
async def record_interaction(
    user_id: str,
    news_id: str,
    interaction_type: str,
    metadata: Optional[Dict[str, Any]] = None,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """Record a user interaction with a news article"""
    success = await recommendation_service.record_user_interaction(
        user_id,
        news_id,
        interaction_type,
        metadata
    )

    if not success:
        raise HTTPException(status_code=404, detail="Failed to record interaction")

    return {"message": "Interaction recorded successfully"}


@app.post("/api/v1/interactions/detail")
async def record_detailed_interaction(
    user_id: str,
    news_id: str,
    interaction_type: str,
    dwell_time_seconds: Optional[int] = None,
    scroll_depth_percent: Optional[int] = None,
    metadata: Optional[Dict[str, Any]] = None
):
    """Record a detailed user interaction with a news article"""
    news = news_collection.find_one({"_id": news_id})
    if not news:
        raise HTTPException(status_code=404, detail="News article not found")

    interaction_data = {
        "user_id": user_id,
        "news_id": news_id,
        "interaction_type": interaction_type,
        "timestamp": datetime.utcnow(),
        "metadata": metadata or {}
    }

    if dwell_time_seconds is not None:
        interaction_data["metadata"]["dwell_time_seconds"] = dwell_time_seconds

    if scroll_depth_percent is not None:
        interaction_data["metadata"]["scroll_depth_percent"] = scroll_depth_percent

    interaction_score = 1.0  # Default score

    if interaction_type == "view":
        interaction_score = 0.5
    elif interaction_type == "click":
        interaction_score = 1.0
    elif interaction_type == "read":
        interaction_score = 2.0
    elif interaction_type == "like":
        interaction_score = 3.0
    elif interaction_type == "share":
        interaction_score = 4.0

    if dwell_time_seconds:
        if dwell_time_seconds > 300:
            interaction_score *= 2.0
        elif dwell_time_seconds > 120:
            interaction_score *= 1.5
        elif dwell_time_seconds > 60:
            interaction_score *= 1.2

    if scroll_depth_percent:
        if scroll_depth_percent > 80:
            interaction_score *= 1.5
        elif scroll_depth_percent > 50:
            interaction_score *= 1.2

    interaction_data["interaction_score"] = interaction_score

    user_interactions_collection.insert_one(interaction_data)

    return {"message": "Interaction recorded successfully"}


@app.post("/api/v1/process/{news_id}")
async def process_news(
    news_id: str,
    background_tasks: BackgroundTasks,
    embedding_service: Any = Depends(get_embedding_service_dep)
):
    """Process a news article (create embeddings, trust analysis, sentiment analysis)"""
    news = news_collection.find_one({"_id": news_id})
    if not news:
        raise HTTPException(status_code=404, detail="News not found")

    background_tasks.add_task(embedding_service.process_news_pipeline, news_id)

    return {"message": f"Processing started for news ID: {news_id}"}


@app.post("/api/v1/metadata/{news_id}")
async def process_metadata(
    news_id: str,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """Process and enrich article metadata"""
    news = news_collection.find_one({"_id": news_id})
    if not news:
        raise HTTPException(status_code=404, detail="News not found")

    result = await recommendation_service.process_article_metadata(news_id)

    if not result["success"]:
        raise HTTPException(status_code=500, detail=result.get("error", "Failed to process metadata"))

    return result


# í˜‘ì—… í•„í„°ë§ ì¶”ì²œ ì—”ë“œí¬ì¸íŠ¸
@app.get("/api/v1/collaborative/recommendations/{user_id}")
async def get_collaborative_recommendations(
    user_id: str,
    limit: int = 10,
    user_analytics_service: Any = Depends(get_user_analytics_service_dep)
):
    """Get collaborative filtering-based recommendations for a user"""
    # í˜‘ì—… í•„í„°ë§ ê¸°ë°˜ ì¶”ì²œ ìš”ì²­
    news_ids = user_analytics_service.get_collaborative_filtering_recommendations(user_id, limit)

    results = []
    for news_id in news_ids:
        news = news_collection.find_one({"_id": news_id})
        if news:
            results.append(NewsSummary(
                id=news["_id"],
                title=news["title"],
                source=news["source"],
                published_date=news["published_date"],
                summary=news.get("summary"),
                image_url=news.get("image_url"),
                trust_score=news.get("trust_score"),
                sentiment_score=news.get("sentiment_score"),
                categories=news.get("categories", [])
            ))

    return results


@app.get("/api/v1/users/stats/{user_id}")
async def get_user_stats(
    user_id: str,
    days: int = 30,
    user_analytics_service: Any = Depends(get_user_analytics_service_dep)
):
    """Get statistics about a user's interactions"""
    stats = user_analytics_service.get_user_interaction_stats(user_id, days)
    return stats


@app.get("/api/v1/users/engagement/{user_id}")
async def get_user_engagement(
    user_id: str,
    days: int = 30,
    user_analytics_service: Any = Depends(get_user_analytics_service_dep)
):
    """Get engagement score for a user"""
    score = user_analytics_service.get_user_engagement_score(user_id, days)
    return {"user_id": user_id, "engagement_score": score}


@app.get("/api/v1/users/preferences/{user_id}")
async def get_user_preferences(
    user_id: str,
    days: int = 90,
    user_analytics_service: Any = Depends(get_user_analytics_service_dep)
):
    """Get category preferences for a user"""
    preferences = user_analytics_service.get_user_category_preferences(user_id, days)
    return {"user_id": user_id, "category_preferences": preferences}


@app.get("/api/v1/users/similar/{user_id}")
async def get_similar_users(
    user_id: str,
    limit: int = 5,
    user_analytics_service: Any = Depends(get_user_analytics_service_dep)
):
    """Get similar users for a user"""
    similar_users = user_analytics_service.get_similar_users(user_id, limit)
    return {"user_id": user_id, "similar_users": similar_users}


# collaborative-filtering ì¶”ì²œ API
@app.get("/api/v1/collaborative-filtering/recommendations/{user_id}")
async def get_cf_recommendations(
    user_id: str,
    limit: int = 10,
    cf_service: Any = Depends(get_collaborative_filtering_service_dep)
):
    """Get collaborative filtering recommendations for a user"""
    # í˜‘ì—… í•„í„°ë§ ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ì¶”ì²œ
    recommended_news_ids = cf_service.get_recommendations_for_user(user_id, limit)

    results = []
    for news_id in recommended_news_ids:
        news = news_collection.find_one({"_id": news_id})
        if news:
            results.append(NewsSummary(
                id=news["_id"],
                title=news["title"],
                source=news["source"],
                published_date=news["published_date"],
                summary=news.get("summary"),
                image_url=news.get("image_url"),
                trust_score=news.get("trust_score"),
                sentiment_score=news.get("sentiment_score"),
                categories=news.get("categories", [])
            ))

    return results


# RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸° API - ì‹¤ì‹œê°„ ë°ì´í„°
@app.get("/api/v1/rss/feeds")
async def get_rss_feeds(
    category: str = None,
    limit: int = 20
):
    """ì‹¤ì œ RSS í”¼ë“œì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ìµœì‹  ë‰´ìŠ¤ ê°€ì ¸ì˜¤ê¸°"""
    try:
        # ì‹¤ì‹œê°„ RSS í”¼ë“œ í¬ë¡¤ë§ì„ ìœ„í•œ ì¸ìŠ¤í„´ìŠ¤ ìƒì„±
        rss_crawler = RSSCrawler()

        # ì‹¤ì œ RSS í”¼ë“œì—ì„œ ìµœì‹  ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìºì‹œ ì—†ìŒ - í•­ìƒ ìµœì‹  ë°ì´í„°)
        articles = rss_crawler.fetch_rss_feeds()

        # LangChain ì„œë¹„ìŠ¤ë¥¼ í†µí•œ ë‰´ìŠ¤ AI ì—…ìŠ¤ì¼€ì¼ë§
        langchain_service = get_langchain_service()

        # ê²°ê³¼ë¥¼ News ê°ì²´ í¬ë§·ìœ¼ë¡œ ë³€í™˜
        news_articles = []
        for article in articles:
            # ì¹´í…Œê³ ë¦¬ í•„í„°ë§ (ìˆëŠ” ê²½ìš°)
            if category and not any(category.lower() in c.lower() for c in article.get("categories", [])):
                continue

            # News ê°ì²´ë¡œ ë³€í™˜
            news_id = article.get("id", str(uuid.uuid4()))
            title = article.get("title", "")
            content = article.get("content", "")
            original_summary = article.get("summary", "")

            # AI ì—…ìŠ¤ì¼€ì¼ë§ - ì½˜í…ì¸ ê°€ ì¶©ë¶„íˆ ìˆëŠ” ê²½ìš°ë§Œ ì²˜ë¦¬
            ai_enhanced = False
            ai_summary = ""
            ai_keywords = []
            trust_score = 0.5  # ê¸°ë³¸ê°’
            sentiment_score = 0  # ê¸°ë³¸ê°’

            # ì½˜í…ì¸  ê¸¸ì´ê°€ ì¶©ë¶„í•œ ê²½ìš°ë§Œ AI ì²˜ë¦¬
            if len(content) > 300 or len(original_summary) > 100:
                try:
                    # AI ìš”ì•½ ìƒì„±
                    ai_result = await langchain_service.analyze_news(title, content if len(content) > 100 else original_summary)

                    if not "error" in ai_result:
                        # AI ìš”ì•½ ì ìš©
                        ai_summary = ai_result.get("summary", "")
                        ai_keywords = ai_result.get("keywords", [])
                        ai_enhanced = True

                        # ì‹ ë¢°ë„ ë° ê°ì • ë¶„ì„ ì¶”ê°€
                        if "importance" in ai_result:
                            trust_score = min(1.0, float(ai_result["importance"]) / 10.0)

                    logger.info(f"AI ìš”ì•½ ìƒì„± ì„±ê³µ: {news_id}")
                except Exception as e:
                    logger.error(f"AI ìš”ì•½ ìƒì„± ì‹¤íŒ¨: {str(e)}")

            # ìµœì¢… ë‰´ìŠ¤ ê°ì²´ êµ¬ì„±
            news = {
                "_id": news_id,
                "title": title,
                "content": content,
                "summary": ai_summary if ai_enhanced and ai_summary else original_summary,
                "url": article.get("link", ""),
                "source": article.get("source", ""),
                "published_date": article.get("published_date", datetime.utcnow()),
                "author": article.get("author", ""),
                "image_url": article.get("image_url", ""),
                "categories": article.get("categories", []),
                "keywords": ai_keywords if ai_enhanced and ai_keywords else article.get("keywords", []),
                "ai_enhanced": ai_enhanced,
                "trust_score": trust_score,
                "sentiment_score": sentiment_score
            }
            news_articles.append(news)

            # ê°œìˆ˜ ì œí•œ
            if len(news_articles) >= limit:
                break

        # ê°€ì¥ ìµœê·¼ ê¸°ì‚¬ ìš°ì„  ì •ë ¬
        news_articles.sort(key=lambda x: x["published_date"], reverse=True)

        return news_articles[:limit]
    except Exception as e:
        logger.error(f"RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"RSS í”¼ë“œ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}")


@app.get("/api/v1/collaborative-filtering/similar-users/{user_id}")
async def get_cf_similar_users(
    user_id: str,
    limit: int = 5,
    cf_service: Any = Depends(get_collaborative_filtering_service_dep)
):
    """Get similar users based on collaborative filtering"""
    similar_users = cf_service.get_similar_users(user_id, limit)
    return {"user_id": user_id, "similar_users": similar_users}


@app.post("/api/v1/rag/index")
async def index_articles(
    background_tasks: BackgroundTasks,
    days: int = 7,
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Index news articles in the vector store"""
    background_tasks.add_task(rag_service.index_news_articles, days)
    return {"message": "Indexing started in background"}


@app.get("/api/v1/rag/search")
async def search_with_rag(
    query: str,
    limit: int = 5,
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Search for news articles with RAG"""
    try:
        results = rag_service.search_news_with_query(query, limit)

        # ê²°ê³¼ í•„ë“œ ìœ íš¨ì„± ê²€ì‚¬ ë° ë³€í™˜
        processed_results = []
        for result in results:
            # ê¸°ë³¸ í•„ë“œ í™•ì¸
            if not result or not isinstance(result, dict):
                continue

            # image_urlì´ HttpUrl í˜•ì‹ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
            if result.get("image_url") and not isinstance(result["image_url"], str):
                result["image_url"] = str(result["image_url"])

            # í•„ìˆ˜ í•„ë“œê°€ ëˆ„ë½ëœ ê²½ìš° ê¸°ë³¸ê°’ ì„¤ì •
            if "id" not in result or not result["id"]:
                if "_id" in result:
                    result["id"] = str(result["_id"])
                else:
                    continue  # IDê°€ ì—†ìœ¼ë©´ ê±´ë„ˆëœ€

            if "title" not in result or not result["title"]:
                result["title"] = "ì œëª© ì—†ìŒ"

            if "summary" not in result or not result["summary"]:
                result["summary"] = result.get("title", "ë‚´ìš© ì—†ìŒ")[:100]

            if "source" not in result or not result["source"]:
                result["source"] = "ë¯¸í™•ì¸ ì¶œì²˜"

            # ìœ íš¨í•œ ê²°ê³¼ë§Œ ì¶”ê°€
            processed_results.append(result)

        return processed_results
    except Exception as e:
        logger.error(f"RAG ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¹ˆ ë°°ì—´ ë°˜í™˜
        return []
        return []


@app.post("/api/v1/rag/summarize/{news_id}")
async def generate_summary(
    news_id: str,
    max_length: int = Query(200, description="ìµœëŒ€ ìš”ì•½ ê¸¸ì´"),
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Generate a summary for a news article using LLM"""
    try:
        # ObjectIdë¡œ ë³€í™˜ ì‹œë„
        try:
            from bson.objectid import ObjectId
            news_id_obj = ObjectId(news_id)
            news = news_collection.find_one({"_id": news_id_obj})
        except:
            # ì‹¤íŒ¨í•˜ë©´ ë¬¸ìì—´ IDë¡œ ì‹œë„
            news = news_collection.find_one({"_id": news_id})

        if not news:
            raise HTTPException(status_code=404, detail="News not found")

        # ì´ë¯¸ ìš”ì•½ì´ ìˆëŠ”ì§€ í™•ì¸
        if "summary" in news and news["summary"] and len(news["summary"].strip()) > 10:
            logger.info(f"Using existing summary for news {news_id}")
            return {"news_id": news_id, "summary": news["summary"].strip()}

        # ìƒˆ ìš”ì•½ ìƒì„±
        # generate_news_summaryëŠ” ë™ê¸° í•¨ìˆ˜ì´ë¯€ë¡œ ì´ë²¤íŠ¸ ë£¨í”„ ì°¨ë‹¨ì„ í”¼í•˜ê¸° ìœ„í•´
        # ë°±ê·¸ë¼ìš´ë“œ íƒœìŠ¤í¬ë¡œ ì‹¤í–‰í•˜ëŠ” ê²ƒì´ ì¢‹ì§€ë§Œ ì§€ê¸ˆì€ ë‹¨ìˆœí™”ë¥¼ ìœ„í•´ ì§ì ‘ í˜¸ì¶œ
        summary = rag_service.generate_news_summary(news_id)

        if not summary:
            # ìš”ì•½ ìƒì„± ì‹¤íŒ¨ ì‹œ ê°„ë‹¨í•œ ìš”ì•½ ìƒì„±
            title = news.get("title", "")
            content = news.get("content", "")
            # ì»¨í…ì¸ ê°€ ë„ˆë¬´ ê¸¸ë©´ ì•ë¶€ë¶„ë§Œ ì‚¬ìš©
            if len(content) > 500:
                simple_summary = content[:500] + "..."
            else:
                simple_summary = content

            return {"news_id": news_id, "summary": simple_summary}

        # ìš”ì•½ ê¸¸ì´ ì œí•œ
        if max_length and len(summary) > max_length:
            summary = summary[:max_length] + "..."

        return {"news_id": news_id, "summary": summary}

    except Exception as e:
        logger.error(f"Error generating summary for news {news_id}: {e}")
        return {"news_id": news_id, "summary": "ìš”ì•½ì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."}


@app.post("/api/v1/rag/chat")
async def chat_with_news(
    user_id: str,
    query: str,
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Chat with news articles using RAG"""
    result = rag_service.chat_with_news(user_id, query)
    return result


@app.post("/api/v1/rag/analyze-topic")
async def analyze_topic(
    topic: str,
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Generate an analysis of a news topic using RAG"""
    result = rag_service.generate_topic_analysis(topic)
    return result


@app.post("/api/v1/rag/switch-vectorstore")
async def switch_vectorstore(
    store_type: str = "chroma",
    rag_service: Any = Depends(get_rag_service_dep)
):
    """Switch between Chroma and FAISS vector stores"""
    rag_service.switch_vectorstore(store_type)
    return {"message": f"Switched to {store_type} vectorstore"}


# ìƒˆë¡œ ì¶”ê°€ëœ API ì—”ë“œí¬ì¸íŠ¸ - ê³ ê¸‰ ìì—°ì–´ ì²˜ë¦¬ ë° AI ê¸°ëŠ¥

class QuestionRequest(BaseModel):
    question: str

class AnalyzeNewsRequest(BaseModel):
    title: str
    content: str

@app.post("/api/v1/news/{news_id}/ask", response_model=Dict[str, str])
async def ask_question_about_news(
    news_id: str,
    request: QuestionRequest,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """ë‰´ìŠ¤ ê¸°ì‚¬ì— ëŒ€í•œ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤."""
    news = news_collection.find_one({"_id": news_id})
    if not news:
        raise HTTPException(status_code=404, detail="News not found")

    answer = await recommendation_service.ask_question_about_news(news_id, request.question)
    return {"answer": answer}

@app.post("/api/v1/news/{news_id}/analyze-langchain")
async def analyze_news_with_langchain(
    news_id: str,
    recommendation_service: Any = Depends(get_recommendation_service_dep)
):
    """LangChainì„ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    result = await recommendation_service.analyze_news_langchain(news_id)

    if not result["success"]:
        raise HTTPException(status_code=500, detail=result.get("error", "Failed to analyze news"))

    return result

@app.post("/api/v1/analyze-news")
async def analyze_news_content(
    request: AnalyzeNewsRequest,
    langchain_service: Any = Depends(get_langchain_service_dep)
):
    """LangChainì„ ì‚¬ìš©í•˜ì—¬ ì œê³µëœ ë‰´ìŠ¤ ì½˜í…ì¸ ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    result = await langchain_service.analyze_news(request.title, request.content)
    return result

@app.post("/api/v1/news/{news_id}/trust-analysis")
async def analyze_news_trustworthiness(
    news_id: str,
    embedding_service: Any = Depends(get_embedding_service_dep)
):
    """BiLSTM ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ì‹ ë¢°ë„ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤."""
    try:
        # ObjectIdë¡œ ë³€í™˜ ì‹œë„
        try:
            news_id_obj = ObjectId(news_id)
            news = news_collection.find_one({"_id": news_id_obj})
        except:
            # ì‹¤íŒ¨í•˜ë©´ ë¬¸ìì—´ IDë¡œ ì‹œë„
            news = news_collection.find_one({"_id": news_id})

        if not news:
            raise HTTPException(status_code=404, detail="News not found")

        # ì´ë¯¸ ì‹ ë¢°ë„ ì ìˆ˜ê°€ ìˆëŠ”ì§€ í™•ì¸
        if "trust_score" in news and news["trust_score"] is not None:
            # ì´ë¯¸ ìˆë‹¤ë©´ ê¸°ì¡´ ì ìˆ˜ ë°˜í™˜
            logger.info(f"Using existing trust score for news {news_id}: {news['trust_score']}")
            return {
                "news_id": news_id,
                "trust_score": news["trust_score"],
                "model": "cached_result"
            }

        # ì‹ ë¢°ë„ ë¶„ì„ ìˆ˜í–‰
        result = await embedding_service.perform_trust_analysis(news_id)

        if result:
            return {
                "news_id": news_id,
                "trust_score": result.trust_score,
                "model": result.model_name
            }
        else:
            # ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ê°’ ë°˜í™˜
            logger.warning(f"No trust analysis result for news {news_id}, using default value")
            return {
                "news_id": news_id,
                "trust_score": 0.5,  # ê¸°ë³¸ ì‹ ë¢°ë„ ì ìˆ˜
                "model": "default_fallback"
            }
    except Exception as e:
        # ëª¨ë“  ì˜ˆì™¸ ì²˜ë¦¬ - 500 ì˜¤ë¥˜ ëŒ€ì‹  ê¸°ë³¸ê°’ ë°˜í™˜
        logger.error(f"Error in trust analysis API: {e}")
        return {
            "news_id": news_id,
            "trust_score": 0.5,  # ê¸°ë³¸ ì‹ ë¢°ë„ ì ìˆ˜
            "model": "error_fallback"
        }

@app.post("/api/v1/news/{news_id}/sentiment-analysis")
async def analyze_news_sentiment(
    news_id: str,
    embedding_service: Any = Depends(get_embedding_service_dep)
):
    """BERT ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ ë‰´ìŠ¤ ê¸°ì‚¬ì˜ ê°ì •ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
    # ObjectIdë¡œ ë³€í™˜ ì‹œë„
    try:
        news_id_obj = ObjectId(news_id)
        news = news_collection.find_one({"_id": news_id_obj})
    except:
        # ì‹¤íŒ¨í•˜ë©´ ë¬¸ìì—´ IDë¡œ ì‹œë„
        news = news_collection.find_one({"_id": news_id})

    if not news:
        raise HTTPException(status_code=404, detail="News not found")

    result = await embedding_service.perform_sentiment_analysis(news_id)
    if not result:
        raise HTTPException(status_code=500, detail="Failed to perform sentiment analysis")

    return {
        "news_id": news_id,
        "sentiment_score": result.sentiment_score,
        "sentiment_label": result.sentiment_label,
        "model": result.model_name
    }

@app.get("/api/v1/news/cold-start", response_model=List[NewsSummary])
async def get_cold_start_recommendations(
    limit: int = 5,
    bert4rec_service = Depends(get_bert4rec_service)
):
    """ì‚¬ìš©ì ë°ì´í„°ê°€ ì—†ëŠ” ìƒíƒœì—ì„œ ì´ˆê¸° ì¶”ì²œì„ ì œê³µí•©ë‹ˆë‹¤."""
    logger.info(f"ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ìš”ì²­: limit={limit}")
    try:
        # BERT4Rec ì„œë¹„ìŠ¤ë¥¼ í†µí•´ ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ê°€ì ¸ì˜¤ê¸°
        recommendations = bert4rec_service.get_cold_start_recommendations(limit=limit)

        if not recommendations or len(recommendations) == 0:
            logger.warning("ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œì´ ì—†ìŠµë‹ˆë‹¤. ìµœì‹  ë‰´ìŠ¤ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            recent_news = list(news_collection.find().sort("published_date", -1).limit(limit))
            recommendations = recent_news

        # ì‘ë‹µ í¬ë§·íŒ…
        result = []
        for news in recommendations:
            summary = NewsSummary(
                id=str(news["_id"]),
                title=news["title"],
                source=news.get("source", "Unknown"),
                published_date=news.get("published_date", datetime.utcnow()),
                summary=news.get("summary", ""),
                image_url=news.get("image_url", ""),
                trust_score=news.get("trust_score", 0.5),
                sentiment_score=news.get("sentiment_score", 0),
                categories=news.get("categories", [])
            )
            result.append(summary)

        logger.info(f"ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ì‘ë‹µ: {len(result)}ê°œ í•­ëª©")
        return result
    except Exception as e:
        logger.error(f"ì½œë“œ ìŠ¤íƒ€íŠ¸ ì¶”ì²œ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=f"Error getting news: {str(e)}")

@app.post("/api/v1/text/embeddings")
async def generate_text_embeddings(
    text: str,
    embedding_service: Any = Depends(get_embedding_service_dep)
):
    """OpenAI ëª¨ë¸ì„ ì‚¬ìš©í•˜ì—¬ í…ìŠ¤íŠ¸ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    embedding = await embedding_service.get_embedding(text)
    return {
        "text": text[:100] + "..." if len(text) > 100 else text,
        "embedding_dimension": len(embedding),
        "embedding": embedding[:5] + ["..."] + embedding[-5:] if embedding else []  # ì²« 5ê°œì™€ ë§ˆì§€ë§‰ 5ê°œ ìš”ì†Œë§Œ ë°˜í™˜
    }

@app.get("/api/v1/models/status")
async def get_models_status(
    model_controller: Any = Depends(get_embedding_service_dep)
):
    """ë“±ë¡ëœ AI ëª¨ë¸ì˜ ìƒíƒœë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    return {
        "openai_embedding": {"status": "active", "type": "embedding"},
        "bilstm_trust": {"status": "active", "type": "trust_analysis"},
        "sentiment_bert": {"status": "active", "type": "sentiment_analysis"},
        "langchain_gpt": {"status": "active", "type": "text_generation"}
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run("app.main:app", host="0.0.0.0", port=8000, reload=True)
