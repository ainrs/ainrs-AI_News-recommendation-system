"""
ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ì„œë¹„ìŠ¤
- RSS 400ê°œ â†’ ì¹´í…Œê³ ë¦¬ë³„ ê· í˜• ë§ì¶˜ ìš°ì„ ìˆœìœ„ ì„ ë³„
- ì¤‘ë³µ ì œê±° ë° í’ˆì§ˆ í‰ê°€
- ì •ì¹˜ ì ë¦¼ í•´ê²°
"""

import logging
import hashlib
from typing import Dict, List, Any, Optional, Tuple
from collections import defaultdict, Counter
from difflib import SequenceMatcher
import re
from datetime import datetime
import numpy as np

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class SmartFilteringService:
    """
    ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ì„œë¹„ìŠ¤
    - ì¹´í…Œê³ ë¦¬ë³„ ê· í˜• ìˆ˜ì§‘
    - í’ˆì§ˆ ê¸°ë°˜ ìš°ì„ ìˆœìœ„
    - ì¤‘ë³µ ì œê±°
    """

    def __init__(self):
        """í•„í„°ë§ ì„œë¹„ìŠ¤ ì´ˆê¸°í™”"""

        # ì¹´í…Œê³ ë¦¬ë³„ ëª©í‘œ ê¸°ì‚¬ ìˆ˜ (ì´ 50ê°œ â†’ ì¹´í…Œê³ ë¦¬ ê· í˜•)
        self.category_targets = {
            "ì¸ê³µì§€ëŠ¥": 8,      # AI ê´€ë ¨ (ë†’ì€ ê´€ì‹¬ë„)
            "ë¹…ë°ì´í„°": 6,      # ë°ì´í„° ê´€ë ¨
            "í´ë¼ìš°ë“œ": 5,      # í´ë¼ìš°ë“œ ê´€ë ¨
            "ë¡œë´‡": 4,          # ë¡œë´‡/ìë™í™”
            "ë¸”ë¡ì²´ì¸": 4,      # ë¸”ë¡ì²´ì¸/ì•”í˜¸í™”í
            "ë©”íƒ€ë²„ìŠ¤": 4,      # VR/AR/ë©”íƒ€ë²„ìŠ¤
            "ITê¸°ì—…": 6,        # IT ê¸°ì—… ë‰´ìŠ¤
            "ìŠ¤íƒ€íŠ¸ì—…": 5,      # ìŠ¤íƒ€íŠ¸ì—…/íˆ¬ì
            "AIì„œë¹„ìŠ¤": 4,      # AI ì„œë¹„ìŠ¤/í”Œë«í¼
            "ì¹¼ëŸ¼": 4           # ì „ë¬¸ê°€ ì¹¼ëŸ¼
        }

        # ì‹ ë¢°í•  ìˆ˜ ìˆëŠ” ì–¸ë¡ ì‚¬ ê°€ì¤‘ì¹˜
        self.source_weights = {
            "yna.co.kr": 1.0,           # ì—°í•©ë‰´ìŠ¤
            "ytn.co.kr": 0.9,           # YTN
            "kbs.co.kr": 0.9,           # KBS
            "news.chosun.com": 0.8,     # ì¡°ì„ ì¼ë³´
            "hani.co.kr": 0.8,          # í•œê²¨ë ˆ
            "khan.co.kr": 0.8,          # ê²½í–¥ì‹ ë¬¸
            "donga.com": 0.8,           # ë™ì•„ì¼ë³´
            "etnews.com": 0.9,          # ì „ìì‹ ë¬¸ (IT ì „ë¬¸)
            "zdnet.co.kr": 0.9,         # ZDNet (IT ì „ë¬¸)
            "bloter.net": 0.7,          # ë¸”ë¡œí„°
            "itworld.co.kr": 0.8,       # IT World
        }

        # í’ˆì§ˆ í‰ê°€ í‚¤ì›Œë“œ
        self.quality_keywords = {
            "high_quality": ["ë°œí‘œ", "ê³µê°œ", "ì¶œì‹œ", "ê°œë°œ", "ì—°êµ¬", "ë¶„ì„", "ë³´ê³ ì„œ", "ì¡°ì‚¬", "ë°œê²¬"],
            "medium_quality": ["ê³„íš", "ì˜ˆì •", "ê²€í† ", "ë…¼ì˜", "íšŒì˜", "í˜‘ì˜"],
            "low_quality": ["ì¶”ì¸¡", "ì†Œë¬¸", "ì˜ˆìƒ", "ê´€ì¸¡", "ì¶”ì •"]
        }

    def filter_articles_smart(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ë©”ì¸ í•¨ìˆ˜
        Args:
            articles: RSSì—ì„œ ìˆ˜ì§‘í•œ ì „ì²´ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        Returns:
            í•„í„°ë§ëœ ìš°ì„ ìˆœìœ„ ê¸°ì‚¬ ë¦¬ìŠ¤íŠ¸
        """
        try:
            logger.info(f"ğŸ” ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ì‹œì‘: {len(articles)}ê°œ ê¸°ì‚¬")

            # 1ë‹¨ê³„: ì¤‘ë³µ ì œê±°
            unique_articles = self._remove_duplicates(articles)
            logger.info(f"ğŸ“‹ ì¤‘ë³µ ì œê±° í›„: {len(unique_articles)}ê°œ ê¸°ì‚¬")

            # 2ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ë¶„ë¥˜ ë° ê°œì„ 
            categorized_articles = self._categorize_articles(unique_articles)

            # 3ë‹¨ê³„: í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°
            scored_articles = self._calculate_quality_scores(categorized_articles)

            # 4ë‹¨ê³„: ì¹´í…Œê³ ë¦¬ë³„ ê· í˜• ì„ ë³„
            balanced_articles = self._balance_categories(scored_articles)
            logger.info(f"âš–ï¸ ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • í›„: {len(balanced_articles)}ê°œ ê¸°ì‚¬")

            # 5ë‹¨ê³„: ìµœì¢… ìš°ì„ ìˆœìœ„ ì •ë ¬
            final_articles = self._final_priority_sort(balanced_articles)

            # í†µê³„ ì¶œë ¥
            self._log_filtering_stats(articles, final_articles)

            return final_articles

        except Exception as e:
            logger.error(f"âŒ ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ ì‹¤íŒ¨: {str(e)}")
            # ì‹¤íŒ¨ ì‹œ ì›ë³¸ì˜ ì•ë¶€ë¶„ ë°˜í™˜
            return articles[:50]

    def _remove_duplicates(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ê¸°ì‚¬ ì œê±°"""
        try:
            unique_articles = []
            seen_urls = set()
            seen_titles = {}

            for article in articles:
                url = article.get('url', '')
                title = article.get('title', '')

                # URL ì¤‘ë³µ ì²´í¬
                if url in seen_urls:
                    continue

                # ì œëª© ìœ ì‚¬ë„ ì²´í¬ (90% ì´ìƒ ìœ ì‚¬í•˜ë©´ ì¤‘ë³µ)
                is_similar = False
                for seen_title in seen_titles.keys():
                    similarity = SequenceMatcher(None, title.lower(), seen_title.lower()).ratio()
                    if similarity > 0.9:
                        is_similar = True
                        # ë” ê¸´ ì œëª©ì„ ì„ íƒ
                        if len(title) > len(seen_title):
                            # ê¸°ì¡´ ê¸°ì‚¬ë¥¼ ìƒˆ ê¸°ì‚¬ë¡œ êµì²´
                            unique_articles = [a for a in unique_articles if a.get('title') != seen_title]
                            seen_titles.pop(seen_title)
                        else:
                            break

                if not is_similar:
                    seen_urls.add(url)
                    seen_titles[title] = True
                    unique_articles.append(article)

            return unique_articles

        except Exception as e:
            logger.error(f"âŒ ì¤‘ë³µ ì œê±° ì‹¤íŒ¨: {str(e)}")
            return articles

    def _categorize_articles(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ê¸°ì‚¬ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ê°œì„ """
        try:
            categorized = []

            for article in articles:
                title = article.get('title', '').lower()
                content = article.get('content', '').lower()
                url = article.get('url', '')

                # ê¸°ì¡´ ì¹´í…Œê³ ë¦¬ê°€ ìˆìœ¼ë©´ ìœ ì§€, ì—†ìœ¼ë©´ ìƒˆë¡œ ë¶„ë¥˜
                existing_categories = article.get('categories', [])

                if not existing_categories or existing_categories == ['ì¸ê³µì§€ëŠ¥']:
                    # ë” ì •ë°€í•œ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜
                    new_category = self._classify_category_improved(title, content, url)
                    article['categories'] = [new_category]
                    article['category_method'] = 'smart_filtering'
                else:
                    article['category_method'] = 'existing'

                categorized.append(article)

            return categorized

        except Exception as e:
            logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜ ì‹¤íŒ¨: {str(e)}")
            return articles

    def _classify_category_improved(self, title: str, content: str, url: str) -> str:
        """ê°œì„ ëœ ì¹´í…Œê³ ë¦¬ ë¶„ë¥˜"""
        text = title + " " + content

        # ì¹´í…Œê³ ë¦¬ë³„ í‚¤ì›Œë“œ ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
        category_scores = {
            "ì¸ê³µì§€ëŠ¥": self._score_keywords(text, [
                ("ai", 3), ("ì¸ê³µì§€ëŠ¥", 3), ("ë¨¸ì‹ ëŸ¬ë‹", 3), ("ë”¥ëŸ¬ë‹", 3),
                ("ì‹ ê²½ë§", 2), ("ì•Œê³ ë¦¬ì¦˜", 2), ("ìë™í™”", 2), ("í•™ìŠµ", 1)
            ]),
            "ë¹…ë°ì´í„°": self._score_keywords(text, [
                ("ë¹…ë°ì´í„°", 3), ("ë°ì´í„°", 3), ("analytics", 3), ("ë¶„ì„", 2),
                ("ë°ì´í„°ë² ì´ìŠ¤", 2), ("ì •ë³´", 1), ("í†µê³„", 2), ("ìˆ˜ì§‘", 1)
            ]),
            "í´ë¼ìš°ë“œ": self._score_keywords(text, [
                ("í´ë¼ìš°ë“œ", 3), ("cloud", 3), ("aws", 3), ("azure", 3), ("gcp", 3),
                ("ì„œë²„", 2), ("í˜¸ìŠ¤íŒ…", 2), ("ì¸í”„ë¼", 2), ("saas", 2)
            ]),
            "ë¡œë´‡": self._score_keywords(text, [
                ("ë¡œë´‡", 3), ("robot", 3), ("ë“œë¡ ", 3), ("ìë™í™”", 2),
                ("ì œì¡°", 2), ("ê³µì¥", 1), ("ì‚°ì—…ìš©", 2), ("ê¸°ê³„", 1)
            ]),
            "ë¸”ë¡ì²´ì¸": self._score_keywords(text, [
                ("ë¸”ë¡ì²´ì¸", 3), ("blockchain", 3), ("ì•”í˜¸í™”í", 3), ("ë¹„íŠ¸ì½”ì¸", 3),
                ("ì´ë”ë¦¬ì›€", 3), ("nft", 3), ("ì½”ì¸", 2), ("crypto", 2)
            ]),
            "ë©”íƒ€ë²„ìŠ¤": self._score_keywords(text, [
                ("ë©”íƒ€ë²„ìŠ¤", 3), ("metaverse", 3), ("ê°€ìƒí˜„ì‹¤", 3), ("vr", 3), ("ar", 3),
                ("ì¦ê°•í˜„ì‹¤", 3), ("3d", 2), ("ê°€ìƒ", 2), ("immersive", 2)
            ]),
            "ITê¸°ì—…": self._score_keywords(text, [
                ("itê¸°ì—…", 3), ("í…Œí¬", 3), ("tech", 3), ("ì†Œí”„íŠ¸ì›¨ì–´", 2),
                ("ê¸°ì—…", 2), ("íšŒì‚¬", 1), ("ê°œë°œ", 2), ("ì„œë¹„ìŠ¤", 1)
            ]),
            "ìŠ¤íƒ€íŠ¸ì—…": self._score_keywords(text, [
                ("ìŠ¤íƒ€íŠ¸ì—…", 3), ("startup", 3), ("ë²¤ì²˜", 3), ("íˆ¬ì", 3),
                ("í€ë”©", 3), ("ì°½ì—…", 2), ("ì‹ ìƒ", 2), ("ì´ˆê¸°", 1)
            ]),
            "AIì„œë¹„ìŠ¤": self._score_keywords(text, [
                ("aiì„œë¹„ìŠ¤", 3), ("í”Œë«í¼", 2), ("ì„œë¹„ìŠ¤", 2), ("ì†”ë£¨ì…˜", 2),
                ("ì•±", 2), ("application", 2), ("ë„êµ¬", 1), ("ì‹œìŠ¤í…œ", 1)
            ]),
            "ì¹¼ëŸ¼": self._score_keywords(text, [
                ("ì¹¼ëŸ¼", 3), ("opinion", 3), ("column", 3), ("ê¸°ê³ ", 3), ("ì‚¬ì„¤", 3),
                ("ì˜ê²¬", 2), ("ë…¼í‰", 2), ("ë¶„ì„", 1), ("ì „ë§", 1)
            ])
        }

        # URL ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜
        for domain, category in [
            ("etnews.com", "ITê¸°ì—…"), ("zdnet.co.kr", "ITê¸°ì—…"),
            ("bloter.net", "ìŠ¤íƒ€íŠ¸ì—…"), ("aitimes.com", "ì¸ê³µì§€ëŠ¥"),
            ("venturesquare.net", "ìŠ¤íƒ€íŠ¸ì—…"), ("platum.kr", "ìŠ¤íƒ€íŠ¸ì—…")
        ]:
            if domain in url:
                category_scores[category] += 2

        # ìµœê³  ì ìˆ˜ ì¹´í…Œê³ ë¦¬ ì„ íƒ
        best_category = max(category_scores, key=category_scores.get)
        max_score = category_scores[best_category]

        # ì ìˆ˜ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ ê¸°ë³¸ê°’
        if max_score < 2:
            return "ITê¸°ì—…"  # ê¸°ë³¸ê°’ì„ ITê¸°ì—…ìœ¼ë¡œ ë³€ê²½ (ì¸ê³µì§€ëŠ¥ ì ë¦¼ ë°©ì§€)

        return best_category

    def _score_keywords(self, text: str, keywords_weights: List[Tuple[str, int]]) -> int:
        """í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì ìˆ˜ ê³„ì‚°"""
        score = 0
        for keyword, weight in keywords_weights:
            count = text.count(keyword)
            score += count * weight
        return score

    def _calculate_quality_scores(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°"""
        try:
            for article in articles:
                title = article.get('title', '')
                content = article.get('content', '')
                url = article.get('url', '')
                source = article.get('source', '')

                score = 5.0  # ê¸°ë³¸ ì ìˆ˜

                # 1. ì¶œì²˜ ì‹ ë¢°ë„
                source_weight = 0.5
                for domain, weight in self.source_weights.items():
                    if domain in url:
                        source_weight = weight
                        break
                score += source_weight * 2

                # 2. ì œëª© í’ˆì§ˆ
                title_score = self._evaluate_title_quality(title)
                score += title_score

                # 3. ë‚´ìš© í’ˆì§ˆ
                content_score = self._evaluate_content_quality(content)
                score += content_score

                # 4. ìµœì‹ ì„± (ë°œí–‰ì¼ ê¸°ì¤€)
                recency_score = self._evaluate_recency(article.get('published_date'))
                score += recency_score

                article['quality_score'] = round(score, 2)
                article['score_breakdown'] = {
                    'source': source_weight * 2,
                    'title': title_score,
                    'content': content_score,
                    'recency': recency_score
                }

            return articles

        except Exception as e:
            logger.error(f"âŒ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨: {str(e)}")
            return articles

    def _evaluate_title_quality(self, title: str) -> float:
        """ì œëª© í’ˆì§ˆ í‰ê°€"""
        score = 0.0

        # ì œëª© ê¸¸ì´ (10-60ìê°€ ì ë‹¹)
        length = len(title)
        if 10 <= length <= 60:
            score += 1.0
        elif length > 60:
            score += 0.5

        # íŠ¹ìˆ˜ë¬¸ìë‚˜ ì˜ë¬¸ë¬¸ íŒ¨í„´
        if '?' in title or '!' in title:
            score += 0.5

        # ë¶€ì •ì  ë‹¨ì–´ (í´ë¦­ë² ì´íŠ¸ ê°ì†Œ)
        clickbait_words = ['ì¶©ê²©', 'ë†€ë¼ìš´', 'ë°˜ì „', 'ëŒ€ë°•', 'ë¯¸ì¹œ']
        if any(word in title for word in clickbait_words):
            score -= 0.5

        # í’ˆì§ˆ í‚¤ì›Œë“œ
        for keyword in self.quality_keywords['high_quality']:
            if keyword in title:
                score += 0.3

        return max(0, score)

    def _evaluate_content_quality(self, content: str) -> float:
        """ë‚´ìš© í’ˆì§ˆ í‰ê°€"""
        score = 0.0

        # ë‚´ìš© ê¸¸ì´
        length = len(content)
        if length > 500:
            score += 1.5
        elif length > 200:
            score += 1.0
        elif length > 100:
            score += 0.5

        # í’ˆì§ˆ í‚¤ì›Œë“œ ë¹„ìœ¨
        high_quality_count = sum(1 for kw in self.quality_keywords['high_quality'] if kw in content)
        low_quality_count = sum(1 for kw in self.quality_keywords['low_quality'] if kw in content)

        score += high_quality_count * 0.2
        score -= low_quality_count * 0.3

        return max(0, score)

    def _evaluate_recency(self, published_date) -> float:
        """ìµœì‹ ì„± í‰ê°€"""
        try:
            if not published_date:
                return 0.5

            if isinstance(published_date, str):
                from datetime import datetime
                published_date = datetime.fromisoformat(published_date.replace('Z', '+00:00'))

            now = datetime.utcnow()
            diff_hours = (now - published_date.replace(tzinfo=None)).total_seconds() / 3600

            # 24ì‹œê°„ ì´ë‚´: 1.0, 48ì‹œê°„ ì´ë‚´: 0.5, ê·¸ ì´í›„: 0.2
            if diff_hours <= 24:
                return 1.0
            elif diff_hours <= 48:
                return 0.5
            else:
                return 0.2

        except Exception:
            return 0.5

    def _balance_categories(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¹´í…Œê³ ë¦¬ë³„ ê· í˜• ì„ ë³„"""
        try:
            # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ì‚¬ ê·¸ë£¹í™”
            category_groups = defaultdict(list)
            for article in articles:
                categories = article.get('categories', ['ê¸°íƒ€'])
                category = categories[0] if categories else 'ê¸°íƒ€'
                category_groups[category].append(article)

            # ì¹´í…Œê³ ë¦¬ë³„ ì •ë ¬ (í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€)
            for category in category_groups:
                category_groups[category].sort(
                    key=lambda x: x.get('quality_score', 0),
                    reverse=True
                )

            # ê· í˜• ì„ ë³„
            balanced_articles = []
            for category, target_count in self.category_targets.items():
                available_articles = category_groups.get(category, [])
                selected_count = min(target_count, len(available_articles))

                selected = available_articles[:selected_count]
                balanced_articles.extend(selected)

                logger.info(f"ğŸ“‚ {category}: {selected_count}/{target_count}ê°œ ì„ ë³„ (available: {len(available_articles)})")

            # ë¶€ì¡±í•œ ê²½ìš° ë‹¤ë¥¸ ì¹´í…Œê³ ë¦¬ì—ì„œ ë³´ì¶©
            total_selected = len(balanced_articles)
            target_total = sum(self.category_targets.values())

            if total_selected < target_total:
                remaining_articles = []
                for category, articles_list in category_groups.items():
                    if category not in self.category_targets:
                        remaining_articles.extend(articles_list)
                    else:
                        # ì´ë¯¸ ì„ ë³„ëœ ê²ƒ ì œì™¸
                        selected_urls = {a['url'] for a in balanced_articles if a.get('categories', [''])[0] == category}
                        extra = [a for a in articles_list if a['url'] not in selected_urls]
                        remaining_articles.extend(extra)

                # í’ˆì§ˆ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬ í›„ ë¶€ì¡±í•œ ë§Œí¼ ì¶”ê°€
                remaining_articles.sort(key=lambda x: x.get('quality_score', 0), reverse=True)
                need_more = target_total - total_selected
                balanced_articles.extend(remaining_articles[:need_more])

            return balanced_articles

        except Exception as e:
            logger.error(f"âŒ ì¹´í…Œê³ ë¦¬ ê· í˜• ì¡°ì • ì‹¤íŒ¨: {str(e)}")
            return articles[:50]

    def _final_priority_sort(self, articles: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ìµœì¢… ìš°ì„ ìˆœìœ„ ì •ë ¬"""
        try:
            # ë³µí•© ì ìˆ˜ ê³„ì‚° (í’ˆì§ˆ + ë‹¤ì–‘ì„±)
            for article in articles:
                base_score = article.get('quality_score', 5.0)

                # ì¹´í…Œê³ ë¦¬ ë‹¤ì–‘ì„± ë³´ë„ˆìŠ¤
                category = article.get('categories', [''])[0]
                if category in ['ë¡œë´‡', 'ë©”íƒ€ë²„ìŠ¤', 'ë¸”ë¡ì²´ì¸']:  # ìƒëŒ€ì ìœ¼ë¡œ ì ì€ ì¹´í…Œê³ ë¦¬
                    base_score += 0.5

                article['final_score'] = base_score

            # ìµœì¢… ì •ë ¬
            articles.sort(key=lambda x: x.get('final_score', 0), reverse=True)

            return articles

        except Exception as e:
            logger.error(f"âŒ ìµœì¢… ì •ë ¬ ì‹¤íŒ¨: {str(e)}")
            return articles

    def _log_filtering_stats(self, original_articles: List, filtered_articles: List):
        """í•„í„°ë§ í†µê³„ ì¶œë ¥"""
        try:
            logger.info("ğŸ“Š ìŠ¤ë§ˆíŠ¸ í•„í„°ë§ í†µê³„:")
            logger.info(f"   ì›ë³¸: {len(original_articles)}ê°œ â†’ ì„ ë³„: {len(filtered_articles)}ê°œ")

            # ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬
            category_dist = Counter()
            for article in filtered_articles:
                categories = article.get('categories', ['ê¸°íƒ€'])
                category_dist[categories[0]] += 1

            logger.info("ğŸ“‚ ì¹´í…Œê³ ë¦¬ë³„ ë¶„í¬:")
            for category, count in category_dist.items():
                target = self.category_targets.get(category, 0)
                logger.info(f"   {category}: {count}ê°œ (ëª©í‘œ: {target})")

            # í‰ê·  í’ˆì§ˆ ì ìˆ˜
            if filtered_articles:
                avg_quality = sum(a.get('quality_score', 0) for a in filtered_articles) / len(filtered_articles)
                logger.info(f"ğŸ“ˆ í‰ê·  í’ˆì§ˆ ì ìˆ˜: {avg_quality:.2f}")

        except Exception as e:
            logger.error(f"âŒ í†µê³„ ì¶œë ¥ ì‹¤íŒ¨: {str(e)}")

# ì „ì—­ ì¸ìŠ¤í„´ìŠ¤
_smart_filtering_service = None

def get_smart_filtering_service() -> SmartFilteringService:
    """SmartFilteringService ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    global _smart_filtering_service
    if _smart_filtering_service is None:
        _smart_filtering_service = SmartFilteringService()
    return _smart_filtering_service
